# Pacotes
#install.packages("dplyr")
#install.packages('nycflights13')
library('ggplot2')
library('dplyr')
# Pacotes
install.packages("dplyr")
install.packages("dplyr")
library('dplyr')
library('nycflights13')
View(flights)
?flights
View(flights)
pop_data <- subset(flights, flights$carrier == 'UA' && flights$carrier == 'DL')
View(pop_data)
pop_data <- subset(flights, flights$carrier == 'UA')
pop_data <- flights %>%
subset(carrier == 'UA') %>%
subset(carrier == 'DL')
pop_data_UA <- flights %>%
subset(carrier == 'UA')
pop_data_DL <- flights %>%
subset(carrier == 'DL')
pop_data <- rbind(pop_data_UA, pop_data_DL)
pop_data <- pop_data[,(carrier, arr_delay)]
pop_data <- pop_data[,names(carrier, arr_delay)]
pop_data <- pop_data[,(~carrier, ~arr_delay)]
pop_data <- pop_data[,9:10]
pop_data <- na.omit(flights) %>%
filter(carrier == 'UA' | carrier == 'DL', arr_delay >= 0) %>%
select(carrier, arr_delay) %>%
group_by(carrier) %>%
sample_n(17000) %>%
ungroup()
View(pop_data)
# Passo 1 - Construa o dataset pop_data com os dados de voos das
# companhias aéreas UA (United Airlines) e DL (Delta Airlines).
# O dataset deve conter apenas duas colunas, nome da companhia e atraso nos voos de chegada.
# Os dados devem ser extraídos do dataset flights para construir o dataset pop_data
# Vamos considerar este dataset como sendo nossa população de voos
?sample_n
?slice_sample
View(sample1)
sample1 <- na.omit(pop_data) %>%
filter(carrier == 'DL') %>%
mutate(sample_id = 1) %>%
sample_n(1000)
View(sample1)
sample2 <- na.omit(pop_data) %>%
filter(carrier == 'UA') %>%
mutate(sample_id = 2) %>%
sample_n(1000)
View(sample2)
View(samples)
samples <- rbind(sample1, sample2)
View(samples)
# Erro padrão
erro_padrao_amostra1 = sd(sample1$arr_delay) / sqrt(nrow(sample1))
erro_padrao_amostra1
erro_padrao_amostra2 = sd(sample2$arr_delay) / sqrt(nrow(sample2))
erro_padrao_amostra2
# Limites inferior e superior
# 1.96 é o valor de z score para 95% de confiança
lower_1 <- mean(sample1$arr_delay) - 1.96 * erro_padrao_amostra1
lower_1
upper_1 <- mean(sample1$arr_delay) + 1.96 * erro_padrao_amostra1
upper_1
# Limites inferior e superior
# 1.96 é o valor de z score para 95% de confiança
mean(sample1$arr_delay)
IC_1 = c(lower_1, upper_1)
IC_1
mean(sample2$arr_delay)
lower_2 <- mean(sample2$arr_delay) - 1.96 * erro_padrao_amostra2
lower_2
upper_2 <- mean(sample2$arr_delay) + 1.96 * erro_padrao_amostra2
upper_2
IC_1
IC_2 = c(lower_2, upper_2)
IC_2
toPLot = summarise( group_by(samples, sample_id), mean = mean(arr_delay))
toPLot
# Limites inferior e superior
# 1.96 é o valor de z score para 95% de confiança
mean(sample1$arr_delay)
mean(sample2$arr_delay)
toPLot = mutate(toPLot, upper = ifelse(toPLot$sample_id == 1), IC_1[2], IC_2[2])
toPLot
View(toPLot)
toPLot = mutate(toPLot, lower = ifelse(toPLot$sample_id == 1, IC_1[1], IC_2[1]))
toPLot = mutate(toPLot, upper = ifelse(toPLot$sample_id == 1, IC_1[2], IC_2[2]))
toPLot
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geopoint() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
# Pacotes
#install.packages("dplyr")
#install.packages('nycflights13')
library('ggplot2')
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geopoint() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
toPLot = summarise(group_by(samples, sample_id), mean = mean(arr_delay) )
toPLot = mutate(toPLot, lower = ifelse(toPLot$sample_id == 1, IC_1[1], IC_2[1]))
toPLot = mutate(toPLot, upper = ifelse(toPLot$sample_id == 1, IC_1[2], IC_2[2]))
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
toPLot = summarise(group_by(samples, sample_id), mean = mean(arr_delay) )
toPLot = mutate(toPLot, lower = ifelse(toPLot$sample_id == 1, IC_1[1], IC_2[1]))
toPLot = mutate(toPLot, upper = ifelse(toPLot$sample_id == 1, IC_1[2], IC_2[2]))
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
str(toPLot)
toPLot$sample_id <- as.factor(toPLot$sample_id)
ggplot(toPLot, aes(x = sample_id, y= mean, colour = sample_id)) +
geom_point() +
geom_errorbar(aes(ymin= lower, ymax = upper), width =.1)
toPLot
DL <- sample_n(filter(pop_data, carrier == 'DL', arr_delay >0), 1000)
UA <- sample_n(filter(pop_data, carrier == 'UA', arr_delay >0), 1000)
View(DL)
se = sd(DL$arr_delay)/sqrt(nrow(DL))
se
mean(DL$arr_delay)
DL_se <- sd(DL$arr_delay)/sqrt(nrow(DL))
DL_se
#Limites inferiores e Superiores  (1.96 p/ 95% confianca )
DL_lower <- DL_mena - 1.96 * DL_se
DL_upper <- DL_mena + 1.96 * DL_se
DL_mean <- mean(DL$arr_delay)
#Limites inferiores e Superiores  (1.96 p/ 95% confianca )
DL_lower <- DL_mean - 1.96 * DL_se
DL_upper <- DL_mean + 1.96 * DL_se
DL_lower
DL_upper
DL_mean
DL_IC <- c(DL_lower, DL_upper)
DL_IC
UA_se <- sd(UA$arr_delay)/sqrt(nrow(UA))
UA_se
UA_mean <- mean(UA$arr_delay)
UA_mean
UA_lower <- UA_mean - 1.96 * UA_se
UA_lower
UA_upper <- UA_mean + 1.96 * UA_se
UA_upper
UA_IC <- c(UA_lower, UA_upper)
UA_IC
UA_mean
t.test(DL$arr_delay, UA$arr_delay, alternative = 'greater')
knitr::opts_chunk$set(echo = TRUE)
# Coletando dados
despesas <- read.csv("despesas.csv")
# Visualizando as variáveis
str(despesas)
# Medias de Tendência Central da variável gastos
summary(despesas$gastos)
# Construindo um histograma
hist(despesas$gastos, main = 'Histograma', xlab = 'Gastos')
# Tabela de contingência das regiões
table(despesas$regiao)
# Explorando relacionamento entre as variáveis: Matriz de Correlação
cor(despesas[c("idade", "bmi", "filhos", "gastos")])
# Nenhuma das correlações na matriz são consideradas fortes, mas existem algumas associações interessantes.
# Por exemplo, a idade e o bmi (IMC) parecem ter uma correlação positiva fraca, o que significa que
# com o aumento da idade, a massa corporal tende a aumentar. Há também uma correlação positiva
# moderada entre a idade e os gastos, além do número de filhos e os gastos. Estas associações implicam
# que, à media que idade, massa corporal e número de filhos aumenta, o custo esperado do seguro saúde sobe.
# Visualizando relacionamento entre as variáveis: Scatterplot
# Perceba que não existe um claro relacionamento entre as variáveis
pairs(despesas[c("idade", "bmi", "filhos", "gastos")])
# Scatterplot Matrix
# install.packages("psych")
library(psych)
# Este gráfico fornece mais informações sobre o relacionamento entre as variáveis
pairs.panels(despesas[c("idade", "bmi", "filhos", "gastos")])
modelo <- lm(gastos ~ idade + filhos + bmi + sexo + fumante + regiao,
data = despesas)
# Similar ao item anterior
modelo <- lm(gastos ~ ., data = despesas)
# Visualizando os coeficientes
modelo
# Prevendo despesas médicas
# Aqui verificamos os gastos previstos pelo modelo que devem ser iguais aos dados de treino
previsao1 <- predict(modelo)
#View(previsao1)
# Prevendo os gastos com Dados de teste
despesasteste <- read.csv("despesas-teste.csv")
#View(despesasteste)
previsao2 <- predict(modelo, despesasteste)
#View(previsao2)
# Mais detalhes sobre o modelo
summary(modelo)
# Adicionando uma variável com o dobro do valor das idades
despesas$idade2 <- despesas$idade ^ 2
# Adicionando um indicador para BMI >= 30
despesas$bmi30 <- ifelse(despesas$bmi >= 30, 1, 0)
# Criando o modelo final
modelo_v2 <- lm(gastos ~ idade + idade2 + filhos + bmi + sexo +
bmi30 * fumante + regiao, data = despesas)
summary(modelo_v2)
# Dados de teste
despesasteste <- read.csv("despesas-teste.csv")
#View(despesasteste)
previsao <- predict(modelo, despesasteste)
class(previsao)
#View(previsao)
setwd("~/Documents/DSA/BigDataAnalyticsR/MachineLearningR")
